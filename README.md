# Accident Detection Using EfficientNetB1 + Transformer

This project implements an Accident Detection System using a hybrid architecture:

- EfficientNetB1 as a frame-level feature extractor

- Transformer-based temporal head to model motion patterns across time

- Real-time prediction overlay on video streams

- Adjustable FPS sampling, sequence length, and prediction stride

The system reads a video, extracts features from sampled frames, feeds a temporal sequence into a transformer model, and outputs an Accident Probability at each timestep.

## ğŸš€ Features

- Video sampling at configurable FPS

- Frame-level preprocessing matching training pipeline

- EfficientNetB1 backbone with ImageNet weights

- Transformer temporal model for sequence classification

- Real-time probability overlay on video frames

- Easy-to-run inference script *(inference.py)*

## ğŸ“ Project Structure
â”œâ”€â”€ inference.py

â”œâ”€â”€ transformer_temporal_head.keras

â”œâ”€â”€ Accident.ipynb (training / experimentation notebook)

â”œâ”€â”€ data/

â”œ    â””â”€â”€ raw/ (example video files)

â””â”€â”€ README.md

## ğŸ› ï¸ Requirements

Install dependencies:

    pip install -r requirements.txt

## ğŸ“¦ Dataset & Model Files

Due to GitHub file size limits, full-resolution videos and trained model
weights are hosted on Google Drive.

ğŸ”— **Google Drive Folder:**
https://drive.google.com/drive/folders/1pHDF4U-Nm0WZssbd0AEjlN7bQxdkAjZH?usp=drive_link

### Folder Structure
- `models/` â†’ transformer_temporal_head.keras  
- `videos/` â†’ accident video clips

## â–¶ï¸ How to Run

1. Place your video inside data/raw/.

2. Update the VARIABLES section in inference.py:

        VIDEO_PATH = "data/raw/your_video.mp4"
        MODEL_WEIGHTS = "transformer_temporal_head.keras"
        SEQ_LEN = 48
        TARGET_FPS = 16

3. Run:

        python inference.py

The script will:

- Extract frames

- Preprocess them

- Run inference

- Show accident probability overlays

Press **Q** to quit the video viewer.

## ğŸ§  Model Details

### EfficientNetB1 Backbone

- Used for frame-level embeddings

- Outputs a 1280-dim feature vector

### Transformer Temporal Head

- Accepts shape: (None, SEQ_LEN, feat_dim)

- Learns accident dynamics over time

## ğŸ“Š Output

Each displayed frame includes:

- Accident Probability (0â€“1)

- Green box â†’ safe

- Red box â†’ above threshold (THRESH = 0.5)

## ğŸ”§ Customization

You can adjust in USER VARIABLES:

- SEQ_LEN â€“ temporal window

- TARGET_FPS â€“ sampling rate

- PRED_EVERY â€“ run transformer less often for speed

- DISPLAY_STRIDE â€“ display fewer frames

## ğŸ“œ License

This project is licensed under the **MIT License**.

You are free to use, modify, and distribute the work.

## âœ¨ Author

Developed by Ponnada Kartikeya Prahit, Pratyay Patra, Komma Pallavi, Shrishti Kumari

For academic, research, and real-time accident detection experimentation.
